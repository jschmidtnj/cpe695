{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "> I pledge my Honor that I have abided by the Stevens Honor System. - Joshua Schmidt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Consider again the example application of Bayes rule in Section 6.2.1 of Tom Mitchell’s textbook (or slide page 6 of Lecture 6). Suppose the doctor decides to order a second laboratory test for the same patient, and suppose the second test returns a positive result as well. What are the posterior probabilities of cancer and -cancer respectively following these two tests? Assume that the two tests are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the two tests are independent, the posterior probabilities for cancer and -cancer are the same following the two tests as they are for the first test. Therefore with a propbility of a single person in the population having this cancer of 0.008, this results in: P(cancer) = 0.008, P(-cancer) = 0.992. P(+|cancer) = 0.98, P(-|cancer) = 0.02. P(+|-cancer) = 0.03, P(-|-cancer) = 0.97.\n",
    "\n",
    "$P(-|-cancer) = \\frac{0.98 \\cdot 0.008}{0.98 \\cdot 0.008 + 0.992 \\cdot 0.03} = 0.97$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "In lecture 6 (page 28-29) we used the Naïve Bayes Algorithm to predict a new instance based on a dataset with 14 examples (page 28). If we only have 12 examples as shown below, what is the prediction results for the same new instance? Show your calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(y) \\cdot P(sun | y) \\cdot P(cool | y) \\cdot P(high | y) \\cdot P(strong | y)$  \n",
    "$\\frac{8}{12} \\cdot \\frac{2}{8} \\cdot \\frac{3}{8} \\cdot \\frac{3}{8} \\cdot \\frac{3}{8}$  \n",
    "$=0.0087890625$\n",
    "\n",
    "$P(n) \\cdot P(sun | n) \\cdot P(cool | n) \\cdot P(high | n) \\cdot P(strong | n)$  \n",
    "$\\frac{4}{12} \\cdot \\frac{3}{4} \\cdot \\frac{1}{4} \\cdot \\frac{3}{4} \\cdot \\frac{2}{4}$  \n",
    "$=0.0234375$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Consider a 2 layer feedforward ANN with 2 inputs a and b, 1 hidden unit c, and 1 output unit d. Run 2 iterations and show the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation function: $\\sigma(y)=\\frac{1}{1+e^{-y}}$\n",
    "\n",
    "training iteration 1:  \n",
    "$output_c = \\sigma(0.1 \\cdot 1 + 0.1 \\cdot 0 + 0.1 \\cdot 1) = \\sigma(0.2) = 0.55$  \n",
    "$output_d = \\sigma(0.1 \\cdot 0.55 + 0.1 \\cdot 1) = \\sigma(0.155) = 0.54$  \n",
    "\n",
    "error for 2 neurons:  \n",
    "$error_d = 0.54 \\cdot (1 - 0.54) \\cdot (1 - 0.54) = 0.115$  \n",
    "$error_c = 0.55 \\cdot (1 - 0.55) \\cdot 0.1 \\cdot 0.115 = 0.0028$  \n",
    "\n",
    "deltas:  \n",
    "$\\delta_{c0} = 0.3 \\cdot 0.0028 \\cdot 1 = 0.00085$  \n",
    "$\\delta_{ca} = 0.3 \\cdot 0.0028 \\cdot 1 = 0.00085$  \n",
    "$\\delta_{d0} = 0.3 \\cdot 0.115 \\cdot 1 = 0.034$  \n",
    "$\\delta_{dc} = 0.3 \\cdot 0.115 \\cdot 0.55 = 0.019$  \n",
    "$\\delta_{cb} = 0.3 \\cdot 0.0028 \\cdot 0 = 0$  \n",
    "\n",
    "new weights:  \n",
    "$w_{c0}=0.1 + 0.00085 = 0.10085$  \n",
    "$w_{ca}=0.1 + 0.00085 = 0.10085$  \n",
    "$w_{d0}=0.1 + 0.034 = 0.134$  \n",
    "$w_{dc}=0.1 + 0.019 = 0.119$  \n",
    "$w_{cb}=0.1 + 0 = 0.1$  \n",
    "\n",
    "tranining iteration 2:  \n",
    "$output_c = \\sigma(0.10085 \\cdot 1 + 0.10085 \\cdot 0 + 0.1 \\cdot 1) = \\sigma(0.20085) = 0.55$  \n",
    "$output_d = \\sigma(0.119 \\cdot 0.55 + 0.134 \\cdot 1) = \\sigma(0.1996) = 0.5497$  \n",
    "\n",
    "error for 2 neurons:  \n",
    "$error_d = 0.5497 \\cdot (1 - 0.5497) \\cdot (1 - 0.5497) = -0.1361$  \n",
    "$error_c = 0.55 \\cdot (1 - 0.55) \\cdot 0.119 \\cdot (-0.1361) = -0.0004$  \n",
    "\n",
    "deltas:  \n",
    "$\\delta_{c0} = 0.3 \\cdot (-0.004) \\cdot 1 + 0.9 \\cdot 0.00085 = -0.0004$  \n",
    "$\\delta_{ca} = 0.3 \\cdot (-0.004) \\cdot 0 + 0.9 \\cdot 0.00085 = -0.00086$  \n",
    "$\\delta_{d0} = 0.3 \\cdot (-0.1361) \\cdot 1 + 0.9 \\cdot 0.034 = -0.01$  \n",
    "$\\delta_{dc} = 0.3 \\cdot (-0.1361) \\cdot 0.55 + 0.9 \\cdot 0.019 = -0.0055$  \n",
    "$\\delta_{cb} = 0.3 \\cdot (-0.004) \\cdot 1 + 0.9 \\cdot 0 = -0.0012$  \n",
    "\n",
    "new weights:  \n",
    "$w_{c0}=0.10085 - 0.0004 = 0.10085$  \n",
    "$w_{ca}=0.10085 + 0.00086 = 0.1016$  \n",
    "$w_{d0}=0.11342 - 0.01 = 0.1242$  \n",
    "$w_{dc}=0.1189 - 0.0055 = 0.1134$  \n",
    "$w_{cb}=0.1 - 0.0012 = 0.0988$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.337494</td>\n",
       "      <td>B5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Crei</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessi</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass  survived                             name     sex      age  sibsp  \\\n",
       "1    1st         1    Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
       "2    1st         1   Allison, Master. Hudson Trevor    male   0.9167      1   \n",
       "3    1st         0     Allison, Miss. Helen Loraine  female   2.0000      1   \n",
       "4    1st         0  Allison, Mr. Hudson Joshua Crei    male  30.0000      1   \n",
       "5    1st         0  Allison, Mrs. Hudson J C (Bessi  female  25.0000      1   \n",
       "\n",
       "   parch  ticket        fare    cabin     embarked boat   body  \\\n",
       "1      0   24160  211.337494       B5  Southampton    2    NaN   \n",
       "2      2  113781  151.550003  C22 C26  Southampton   11    NaN   \n",
       "3      2  113781  151.550003  C22 C26  Southampton  NaN    NaN   \n",
       "4      2  113781  151.550003  C22 C26  Southampton  NaN  135.0   \n",
       "5      2  113781  151.550003  C22 C26  Southampton  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "1                     St Louis, MO  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  \n",
       "5  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('./titanic.csv', index_col=0)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_vectorizer = DictVectorizer(sparse=False)\n",
    "titanic_feature_cols = ['pclass', 'sex', 'age', 'sibsp']\n",
    "target_col = 'survived'\n",
    "titanic_data = titanic_df[[*titanic_feature_cols, target_col]].dropna()\n",
    "titanic_features = titanic_data[titanic_feature_cols]\n",
    "X = titanic_vectorizer.fit_transform(titanic_features.to_dict('records'))\n",
    "titanic_vectorizer.get_feature_names()\n",
    "y = titanic_data[target_col].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/anaconda3/envs/cpe695/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(2, 5),\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', activation='logistic', alpha=1e-05,\n",
    "                     hidden_layer_sizes=(2,5), random_state=random_state)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample survive predicted = 55.193%\n",
      "in-sample fatalities predicted = 96.192%\n",
      "out-of-sample survive predicted = 51.111%\n",
      "out-of-sample fatalities predicted = 96.667%\n"
     ]
    }
   ],
   "source": [
    "train_survive_indexes = np.where(y_train == 1)[0]\n",
    "train_survive_predictions = clf.predict(X_train[train_survive_indexes])\n",
    "inv_train_survive_predictions = np.logical_not(train_survive_predictions).astype(int)\n",
    "print(f'in-sample survive predicted = {(len(train_survive_predictions) - np.count_nonzero(inv_train_survive_predictions)) / len(train_survive_predictions) * 100:.3f}%')\n",
    "\n",
    "train_fatality_indexes = np.where(y_train == 0)[0]\n",
    "train_fatality_predictions = clf.predict(X_train[train_fatality_indexes])\n",
    "print(f'in-sample fatalities predicted = {(len(train_fatality_predictions) - np.count_nonzero(train_fatality_predictions)) / len(train_fatality_predictions) * 100:.3f}%')\n",
    "\n",
    "test_survive_indexes = np.where(y_test == 1)[0]\n",
    "test_survive_predictions = clf.predict(X_test[test_survive_indexes])\n",
    "inv_test_survive_predictions = np.logical_not(test_survive_predictions).astype(int)\n",
    "print(f'out-of-sample survive predicted = {(len(test_survive_predictions) - np.count_nonzero(inv_test_survive_predictions)) / len(test_survive_predictions) * 100:.3f}%')\n",
    "\n",
    "test_fatality_indexes = np.where(y_test == 0)[0]\n",
    "test_fatality_predictions = clf.predict(X_test[test_fatality_indexes])\n",
    "print(f'out-of-sample fatalities predicted = {(len(test_fatality_predictions) - np.count_nonzero(test_fatality_predictions)) / len(test_fatality_predictions) * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different hidden layer sizes\n"
     ]
    }
   ],
   "source": [
    "print('different hidden layer sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/anaconda3/envs/cpe695/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(5, 4),\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', activation='logistic', alpha=1e-05,\n",
    "                     hidden_layer_sizes=(5,4), random_state=random_state)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample survive predicted = 66.172%\n",
      "in-sample fatalities predicted = 90.180%\n",
      "out-of-sample survive predicted = 63.333%\n",
      "out-of-sample fatalities predicted = 85.000%\n"
     ]
    }
   ],
   "source": [
    "train_survive_indexes = np.where(y_train == 1)[0]\n",
    "train_survive_predictions = clf.predict(X_train[train_survive_indexes])\n",
    "inv_train_survive_predictions = np.logical_not(train_survive_predictions).astype(int)\n",
    "print(f'in-sample survive predicted = {(len(train_survive_predictions) - np.count_nonzero(inv_train_survive_predictions)) / len(train_survive_predictions) * 100:.3f}%')\n",
    "\n",
    "train_fatality_indexes = np.where(y_train == 0)[0]\n",
    "train_fatality_predictions = clf.predict(X_train[train_fatality_indexes])\n",
    "print(f'in-sample fatalities predicted = {(len(train_fatality_predictions) - np.count_nonzero(train_fatality_predictions)) / len(train_fatality_predictions) * 100:.3f}%')\n",
    "\n",
    "test_survive_indexes = np.where(y_test == 1)[0]\n",
    "test_survive_predictions = clf.predict(X_test[test_survive_indexes])\n",
    "inv_test_survive_predictions = np.logical_not(test_survive_predictions).astype(int)\n",
    "print(f'out-of-sample survive predicted = {(len(test_survive_predictions) - np.count_nonzero(inv_test_survive_predictions)) / len(test_survive_predictions) * 100:.3f}%')\n",
    "\n",
    "test_fatality_indexes = np.where(y_test == 0)[0]\n",
    "test_fatality_predictions = clf.predict(X_test[test_fatality_indexes])\n",
    "print(f'out-of-sample fatalities predicted = {(len(test_fatality_predictions) - np.count_nonzero(test_fatality_predictions)) / len(test_fatality_predictions) * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "|                      | in sample survive | in sample fatalities | out of sample survive | out of sample fatalities |\n",
    "|----------------------|-------------------|----------------------|-----------------------|--------------------------|\n",
    "| pruned decision tree | 56.380%           | 97.595%              | 48.889%               | 96.667%                  |\n",
    "| first ANN            | 55.193%           | 96.192%              | 51.111%               | 96.667%                  |\n",
    "| second ANN           | 66.172%           | 90.180%              | 63.333%               | 85.000%                  |\n",
    "\n",
    "The trained ANN's have comporable performance to the pruned decision tree. By changing the size of the hidden layers you can achieve better performance for fatalities vs survive classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpe695",
   "language": "python",
   "name": "cpe695"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
